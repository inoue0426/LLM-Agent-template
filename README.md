# LLM-Agent-template

## Setting 

1. Get ollama (https://ollama.com/) and pull models whatever you want to use.

```sh
via â¬¢ v16.4.0 via ðŸ…’ multi 
ollama pull llama3
```

2. Run litellm in a terminal.

```sh
via â¬¢ v16.4.0 via ðŸ…’ multi 
âžœ litellm --model ollama_chat/llama3
```

3. Run Python files in the terminal

```sh
python main.py
```
